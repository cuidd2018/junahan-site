#+title:  Microsoft interview prepare
#+author:  Junahan
#+email:  junahan@outlook.com
#+date:  2018-10-11
#+hugo_base_dir: ../
#+hugo_auto_set_lastmod: t
#+hugo_tags: Hugo ox-hugo orgmode
#+hugo_categories: Emacs
#+hugo_draft: true
#+language:  cn
#+options:  H:3 num:nil toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+options:  TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+infojs_opt:  view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+license:  CC BY 4.0


* Abstract

* Data Structure and Algorithm Analysis
** Computational Complexity
*** Traveling Salesman Problem

** Graph


- DAG - Directed acyclic graph 


* Algorithmic Paradigm
** Greedy Algorithm (贪心算法)
A greedy algorithm is an [[https://en.wikipedia.org/wiki/Algorithmic_paradigm][algorithmic paradigm]] that follows the problem solving heuristic of making the locally optimal choice at each stage[1] with the intent of finding a global optimum. In many problems, a greedy strategy does not usually produce an optimal solution, but nonetheless a greedy heuristic may yield locally optimal solutions that approximate a globally optimal solution in a reasonable amount of time.

*** Specifics
Greedy algorithms produce good solutions on some mathematical problems, but not on others. Most problems for which they work will have two properties:

*Greedy choice property*

We can make whatever choice seems best at the moment and then solve the subproblems that arise later. The choice made by a greedy algorithm may depend on choices made so far, but not on future choices or all the solutions to the subproblem. It iteratively makes one greedy choice after another, reducing each given problem into a smaller one. In other words, a greedy algorithm never reconsiders its choices. This is the main difference from dynamic programming, which is exhaustive and is guaranteed to find the solution. After every stage, dynamic programming makes decisions based on all the decisions made in the previous stage, and may reconsider the previous stage's algorithmic path to solution.

*Optimal substructure*

"A problem exhibits optimal substructure if an optimal solution to the problem contains optimal solutions to the sub-problems."[2]

*** Examples
- Making Change - 
- Traveling Salesman Problem - the following heuristic: At each step of the journey, visit the nearest unvisited city.
- [[https://www.hackerearth.com/zh/practice/algorithms/graphs/minimum-spanning-tree/tutorial/][Minimum Spanning Tree]]
- [[https://www.hackerearth.com/zh/practice/algorithms/graphs/shortest-path-algorithms/tutorial/][Dijkstra’s algorithm for shortest paths from a single source]]
- [[https://en.wikipedia.org/wiki/Huffman_coding][Huffman codes]] ( data-compression codes )

** [[https://en.wikipedia.org/wiki/Divide_and_conquer_algorithms][Divid and Conquer Algorithm]] (分而治之)
In computer science, divide and conquer is an algorithm design paradigm based on multi-branched recursion. A divide and conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.

Examples:
- Quick Sort - 

** [[https://en.wikipedia.org/wiki/Dynamic_programming][Dynamic Programming]]

** [[https://en.wikipedia.org/wiki/Prune_and_search][Prune and Search]] 

* Reference
1. Greedy Algorithm - https://en.wikipedia.org/wiki/Greedy_algorithm.
2. Algorhtm Paradigm - https://en.wikipedia.org/wiki/Algorithmic_paradigm.
3. Graph Representation - https://www.hackerearth.com/zh/practice/algorithms/graphs/graph-representation/tutorial/.



